{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deploying a machine Learning Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSheZ3hgn8RpLzdiCrlpYE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amanjyot62/Data-Science-Using-Pyhton/blob/master/Deploying_a_machine_Learning_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6sh9Ayv5kmv",
        "colab_type": "text"
      },
      "source": [
        "#Deploying a Machine Learning Model\n",
        "\n",
        "Building a web API is the most popular way to expose a machine learning model in a production environment. But before diving into this, we need to understand what a web API is first.\n",
        "\n",
        "A web API (also known as a web service) is a programming interface that allows web communication between a client and a server. It is usually composed of one or multiple endpoints that expose resources from the server side that can be accessed externally. A web API relies on a request-response messaging mechanism for handling received requests and sent responses.\n",
        "\n",
        "But we need to train a model first. Let's build a classifier with RandomForest algorithm with the Bank Marketing dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMa5lnIe6c_j",
        "colab_type": "text"
      },
      "source": [
        "First, we need to import the required packages:\n",
        "\n",
        "Then we will load the dataset into a DataFrame:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sa16J7Z6KAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter03/bank-full.csv'\n",
        "df = pd.read_csv(file_url, sep=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCiNxgNB6pgk",
        "colab_type": "text"
      },
      "source": [
        "Then we will extract the response variable, which is the y column in this dataset, using the .pop() method from pandas:\n",
        "After this, we need to one-hot encode the categorical variables using the .get_dummies() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Oq4rWcD6qUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df.pop('y')\n",
        "df_dummies = pd.get_dummies(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxdNn4Wi6yUR",
        "colab_type": "text"
      },
      "source": [
        "The final step before modeling is to split the data into training and testing sets. To do so, we will use the train_test_split() function from sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKltcXgZ62ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_dummies, y, test_size=0.33, random_state=42)\n",
        "rf_model = RandomForestClassifier(random_state=8)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwmM_Lzo7BWk",
        "colab_type": "text"
      },
      "source": [
        "We can also predict the outcome on a single record from the test set. sklearn models expect a 2-dimensional array as input, so we need to wrap our record into another list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrnWx38s7CJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_model.predict([X_test.iloc[3776,]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqDM1Xme7HAQ",
        "colab_type": "text"
      },
      "source": [
        "Note: We are not interested in improving the performance of this model. We just need a trained model that we can deploy on our Flask app.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JglRdI-67L5A",
        "colab_type": "text"
      },
      "source": [
        "Before adding our model to the Flask app, we need to save it as a file. We will use the .dump() method from the joblib package:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4uFW3FL7Jus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "joblib.dump(rf_model, \"model.pkl\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz5jexCA7NpB",
        "colab_type": "text"
      },
      "source": [
        "Your model is saved on the filesystem, and the filename is model.pkl. To load this model, we can use the .load() method:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oup-MDqy7P36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model = joblib.load(\"model.pkl\")\n",
        "saved_model.predict([X_test.iloc[3776,]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxbP71d7W76",
        "colab_type": "text"
      },
      "source": [
        "Now we can create a new API endpoint called /predict that will predict the outcome using this model on the data it receives as input. Within the API function, we need to read the input data, perform the prediction with our pre-loaded model, convert the prediction into a string using the array2string method from numpy, and finally convert it to JSON using jsonify()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JqixJUh7YK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def rf_predict():\n",
        "  data = request.get_json()\n",
        "  prediction = saved_model.predict(data)\n",
        "  str_pred = np.array2string(prediction)\n",
        "  return jsonify(str_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-02hH5I07b_w",
        "colab_type": "text"
      },
      "source": [
        "Now we need to send a POST request with the record we want to get prediction from. We will use the same example as previously: record number 3776. First, we need to convert it into a list by using the .to_list() method from pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYyyTlYC7cyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "record = X_test.iloc[3776,].to_list()\n",
        "record\n",
        "j_data = json.dumps([record])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuFzlq6d7mJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Finally, we can send a POST request with this converted record:\n",
        "\n",
        "r = requests.post(\"http://172.28.0.2/predict\", data=j_data, headers=headers)\n",
        "r.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMvPYYBv7sKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Great! We got the exact same prediction as before, but this time we got it from our model deployed as a Flask app. As you can see, it is relatively simple to expose a machine learning algorithm as a web API."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}